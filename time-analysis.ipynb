{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pymysql\n",
    "%pip install sshtunnel\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import paramiko\n",
    "from os.path import expanduser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = expanduser('~')\n",
    "mypkey = paramiko.RSAKey.from_private_key_file( home + \"/.ssh/id_rsa\")\n",
    "\n",
    "sql_hostname = '127.0.0.1'\n",
    "sql_username = 'readonly'\n",
    "sql_password = None\n",
    "sql_main_database = 'ML3_mirror'\n",
    "sql_port = 3306\n",
    "ssh_host = 'flagon.cs.umn.edu'\n",
    "ssh_user = 'kanna128'\n",
    "ssh_port = 22\n",
    "sql_ip = '1.1.1.1.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(values, labels, max_vals, scale):\n",
    "  bars = plt.bar(range(len(values[1])), values[1], color=(0.2, 0.4, 0.6, 0.6))\n",
    "\n",
    "  if((isinstance(scale[1], int))):\n",
    "    for bar in bars:\n",
    "      yval = bar.get_height()\n",
    "      plt.text(bar.get_x() + 0.5*bar.get_width(), yval + values[2], yval)\n",
    "\n",
    "  xticks = []\n",
    "  yticks = []\n",
    "\n",
    "  if(scale[0] != 0):\n",
    "    xmax = max_vals[0]\n",
    "    xscale = scale[0]\n",
    "    for k in np.arange(0, xmax, xscale):\n",
    "      xticks.append(k)\n",
    "    plt.xticks(xticks)\n",
    "  else:\n",
    "    plt.xticks(range(len(values[0])), values[0])\n",
    "  \n",
    "  ymax = max_vals[1]\n",
    "  yscale = scale[1]\n",
    "\n",
    "  for k in np.arange(0, ymax, yscale):\n",
    "    yticks.append(k)\n",
    "  plt.yticks(yticks)\n",
    "\n",
    "  plt.xlabel(labels[0])\n",
    "  plt.ylabel(labels[1])\n",
    "  plt.ylim(0,max_vals[1])\n",
    "\n",
    "  if(max_vals[0] != 0):\n",
    "    plt.xlim(0, max_vals[0])\n",
    "  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE = \"{\\\"engineId\\\":\\\"baseline\\\"}\"\n",
    "ITEM_ITEM = \"{\\\"engineId\\\":\\\"item-item\\\"}\"\n",
    "SVD = \"{\\\"engineId\\\":\\\"svd\\\"}\"\n",
    "PICK_GROUPS = \"{\\\"engineId\\\":\\\"pick-groups\\\"}\"\n",
    "\n",
    "LONG_TO_SHORT = {BASELINE: \"baseline\", ITEM_ITEM: \"item-item\", SVD:\"svd\", PICK_GROUPS: \"pick-groups\"}\n",
    "SHORT_TO_LONG = {\"baseline\": BASELINE, \"item-item\":ITEM_ITEM, \"svd\":SVD, \"pick-groups\":PICK_GROUPS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### PRIMARY_DICTS #######################################################\n",
    "\n",
    "def primary_dicts(users, change_events, fields):\n",
    "    \n",
    "    users_count = users.shape[0]\n",
    "    uid = fields[0]\n",
    "    begin = fields[1]\n",
    "    \n",
    "    pattern_list_dict = {} # dict to store key=userId, val=curralg in the iteration process\n",
    "    \n",
    "    for k in range(users_count):\n",
    "        userId = users.at[k, uid]\n",
    "        first_item = [ SHORT_TO_LONG[users.at[k, begin]] ] # following the format of log_action.log_Json for future comparisons\n",
    "        pattern_list_dict[userId] = first_item\n",
    "\n",
    "    changes_dict = {} # needed to later calculate median changes per user\n",
    "    changes_count = change_events.shape[0]\n",
    "    cmp_field = fields[2]\n",
    "    # loop to count number of changes correctly; comparing next with prev algorithm\n",
    "    for i in range(changes_count):\n",
    "        userId = change_events.at[i, uid]\n",
    "        item_to_cmp = change_events.at[i, cmp_field]\n",
    "        if(pattern_list_dict[userId][-1] != item_to_cmp):\n",
    "            changes_dict[userId] = 1 + changes_dict.get(userId, 0)\n",
    "            pattern_list_dict[userId].append(item_to_cmp)\n",
    "\n",
    "    return (changes_dict, pattern_list_dict)\n",
    "\n",
    "################################################## FIG_2 #######################################################\n",
    "\n",
    "def fig_2(recchange_dict, changes_dict):\n",
    "    # count_dict: key=algorithm, val=(no. of users initially assigned, no. of users initially assigned and switched at least once)\n",
    "    count_dict = {\"baseline\":[0,0], \"item-item\":[0,0], \"svd\":[0,0], \"pick-groups\":[0,0]}\n",
    "    for userId,recalg_list in recchange_dict.items():\n",
    "        recalg = LONG_TO_SHORT[recalg_list[0]]\n",
    "        count_dict[recalg][0] +=1\n",
    "        if userId in changes_dict.keys():\n",
    "            count_dict[recalg][1] += 1\n",
    "    \n",
    "    baseline = count_dict[\"baseline\"][1]/count_dict[\"baseline\"][0]\n",
    "    item_item = count_dict[\"item-item\"][1]/count_dict[\"item-item\"][0]\n",
    "    svd = count_dict[\"svd\"][1]/count_dict[\"svd\"][0]\n",
    "\n",
    "    values = [[\"baseline\", \"item-item\", \"svd\"], [baseline, item_item, svd], 0.01]\n",
    "    return (count_dict, values)\n",
    "\n",
    "############################################## TABLE_2 #########################################################\n",
    "\n",
    "def table_2(changes_dict, count_dict):\n",
    "  changes_dict = {id:list for id,list in changes_dict.items() if len(list)>1}\n",
    "  patterns = {}\n",
    "  for id, list in changes_dict.items():\n",
    "    new_list = []\n",
    "    for alg in list:\n",
    "      new_alg = LONG_TO_SHORT[alg]\n",
    "      new_list.append(new_alg)\n",
    "    recalg_tup = tuple(new_list)\n",
    "    changes_dict[id] = recalg_tup\n",
    "    patterns[recalg_tup] = 0\n",
    "    \n",
    "  for recalg_tup in changes_dict.values():\n",
    "    patterns[recalg_tup] += 1\n",
    "  \n",
    "  patterns_found = set()\n",
    "\n",
    "  for id, recalg_tup in changes_dict.items():\n",
    "    initial = recalg_tup[0]\n",
    "    count = 0\n",
    "    if recalg_tup in patterns.keys():\n",
    "      count = patterns[recalg_tup]\n",
    "    if(count>7 and count<53):\n",
    "      percentage = (count/count_dict[initial][1])*100\n",
    "      pattern_info = (\"pattern: {} | count: {} | percentage: {}\".format(recalg_tup, count, percentage))\n",
    "      patterns_found.add(pattern_info)\n",
    "  \n",
    "  for item in patterns_found:\n",
    "    print(item)\n",
    "\n",
    "################################################# FIG_4 ########################################################\n",
    "\n",
    "def fig_4(changes_dict, range):\n",
    "    transitions_dict = {}\n",
    "    \n",
    "    # range check -- running it on data where the range is outside of 20\n",
    "    # accepting the broadest possible input | returning the most specific answer\n",
    "    # for k in range(20):\n",
    "    #     transitions_dict[k+1] = 0\n",
    "    lower_bound = range[0]\n",
    "    upper_bound = range[1]\n",
    "    for list in changes_dict.values():\n",
    "        transition_count = len(list) - 1\n",
    "        if transition_count>lower_bound and transition_count<upper_bound: \n",
    "            transitions_dict[transition_count] = 1 + transitions_dict.get(transition_count, 0)\n",
    "    return transitions_dict\n",
    "\n",
    "######################################## SSH_CONNECTION #################################################\n",
    "\n",
    "def SSH_connection(query):\n",
    "  with SSHTunnelForwarder(\n",
    "        (ssh_host, ssh_port),\n",
    "        ssh_username=ssh_user,\n",
    "        ssh_pkey=mypkey,\n",
    "        remote_bind_address=(sql_hostname, sql_port)) as tunnel:\n",
    "    conn = pymysql.connect(host='127.0.0.1', user=sql_username,\n",
    "                            passwd=sql_password, db=sql_main_database,\n",
    "                            port=tunnel.local_bind_port)\n",
    "    print('connection done')\n",
    "    df_result = pd.read_sql_query(query,conn)\n",
    "  \n",
    "  return df_result\n",
    "\n",
    "#################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection done\n",
      "Users: 3005\n"
     ]
    }
   ],
   "source": [
    "# CALCULATING NUMBER OF USERS \n",
    "query_users = ''' SELECT expt_user.group, expt_user.userId from ML3_mirror.expt_user WHERE \n",
    "                exptId = 'listcmp-long' AND started <'2015-04-01' \n",
    "                AND status = 'RANDOMLY_ASSIGNED' '''\n",
    "users = SSH_connection(query_users)\n",
    "print(\"Users: {}\".format(users.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection done\n",
      "query done\n",
      "12029\n"
     ]
    }
   ],
   "source": [
    "# NUMBER OF CHANGE EVENTS \n",
    "query_change = '''SELECT userId, logJson, tstamp, action from ML3_mirror.log_action WHERE EXISTS \n",
    "                (SELECT userId from ML3_mirror.expt_user where expt_user.userId = log_action.userId \n",
    "                AND expt_user.exptId='listcmp-long' \n",
    "                AND expt_user.status='RANDOMLY_ASSIGNED') \n",
    "                AND log_action.action='recommender-change' \n",
    "                AND log_action.tstamp<'2015-04-01' ORDER BY log_action.tstamp'''\n",
    "change_events = SSH_connection(query_change)\n",
    "print(\"query done\")\n",
    "print(change_events.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommender change events:  11418\n",
      "Users switching at least once:  748\n",
      "Median changes per user w/ at least 1 change:  3\n"
     ]
    }
   ],
   "source": [
    "# SETTING UP DICTS \n",
    "dicts = primary_dicts(users, change_events, ('userId', 'group', 'logJson'))\n",
    "changes_dict = dicts[0]\n",
    "recchange_dict = dicts[1]\n",
    "\n",
    "\n",
    "# TABLE 1\n",
    "print(\"Recommender change events: \", sum(changes_dict.values()))\n",
    "changes_dict = {key:val for key,val in changes_dict.items() if val !=0}\n",
    "print(\"Users switching at least once: \", len(changes_dict.values()))\n",
    "print(\"Median changes per user w/ at least 1 change: \", int(np.median(list(changes_dict.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE 2 \n",
    "func_out = fig_2(recchange_dict, changes_dict)\n",
    "values = func_out[1]\n",
    "count_dict = func_out[0]\n",
    "draw_graph(values, [\"Initial Algorithm\", \"Proportion of Users Switching\"], [0, 0.35], [0, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABLE 2 \n",
    "table_2(recchange_dict, count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE 3\n",
    "for key in count_dict.keys():\n",
    "    count_dict[key] = 0\n",
    "\n",
    "for userId, recalg_tup in recchange_dict.items():\n",
    "    if(userId in changes_dict.keys()):\n",
    "        alg = LONG_TO_SHORT[recalg_tup[-1]]\n",
    "        count_dict[alg] += 1\n",
    "\n",
    "values = [[\"baseline\", \"item-item\", \"pick-groups\", \"svd\"], \n",
    "        [count_dict[\"baseline\"], count_dict[\"item-item\"], \n",
    "        count_dict[\"pick-groups\"], count_dict[\"svd\"]], \n",
    "        8]\n",
    "draw_graph(values, [\"Final Selected Algorithm\", \"# of users\"], [0, 400], [0, 100])\n",
    "\n",
    "# FIGURE 4\n",
    "func_out = fig_4(recchange_dict, (0, 20))\n",
    "plt.hist(func_out.keys(), weights=func_out.values(), bins = range(21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection done\n",
      "   count(*)\n",
      "0    621277\n"
     ]
    }
   ],
   "source": [
    "query_time = '''SELECT count(*) from ML3_mirror.log_action WHERE EXISTS \n",
    "                (SELECT userId from ML3_mirror.expt_user where expt_user.userId = log_action.userId \n",
    "                AND expt_user.exptId='listcmp-long' \n",
    "                AND expt_user.status='RANDOMLY_ASSIGNED')\n",
    "                AND log_action.tstamp<'2015-04-01' ORDER BY userId'''\n",
    "# query_time = ''' SELECT userId,tstamp from ML3_mirror.log_action limit 10 '''\n",
    "transition_times = SSH_connection(query_time)\n",
    "print(transition_times)\n",
    "# rows = transition_times.shape[0]\n",
    "\n",
    "# 621277 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_items(dict_in, desired_diff):\n",
    "    dict_diffs = dict_in\n",
    "    for key,val in dict_diffs.items():\n",
    "        if val>desired_diff:\n",
    "            dict_diffs.pop(key)\n",
    "    return len(dict_diffs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_time = '''SELECT userId, action, tstamp from ML3_mirror.log_action WHERE EXISTS \n",
    "                (SELECT userId from ML3_mirror.expt_user where expt_user.userId = log_action.userId \n",
    "                AND expt_user.exptId='listcmp-long' \n",
    "                AND expt_user.status='RANDOMLY_ASSIGNED')\n",
    "                AND log_action.tstamp<'2015-04-01' ORDER BY log_action.tstamp'''\n",
    "transition_times = SSH_connection(query_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_users = ''' SELECT userId, MIN(tstamp) as tstamp from ML3_mirror.user_login WHERE EXISTS \n",
    "                  (SELECT userId from ML3_mirror.expt_user where expt_user.userId = user_login.userId \n",
    "                  AND expt_user.exptId='listcmp-long' \n",
    "                  AND expt_user.status='RANDOMLY_ASSIGNED') GROUP BY userId '''\n",
    "start_times_raw = SSH_connection(query_users)\n",
    "start_times_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection done\n",
      "2014-10-31 15:22:29\n",
      "2015-03-31 23:49:59\n",
      "connection done\n",
      "483045\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2h/tx4dx_bn6wvbjmwvb84kz59w0000gn/T/ipykernel_1662/898766785.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0muserId\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_times_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mstarted_at\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserId\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_times_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tstamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarted_at\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#2999\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "print(transition_times['tstamp'].min())\n",
    "print(transition_times['tstamp'].max())\n",
    "\n",
    "# k=0\n",
    "# for k in range(start_times_raw.shape[0]):\n",
    "#     if k <15:\n",
    "#         print(start_times_raw)\n",
    "#     else:\n",
    "#         break\n",
    "#     k += 1\n",
    "# print(\"query_users done\")\n",
    "\n",
    "# query_time = '''SELECT count(DISTINCT userId) from ML3_mirror.log_action WHERE EXISTS \n",
    "#                 (SELECT userId from ML3_mirror.expt_user where expt_user.userId = log_action.userId \n",
    "#                 AND expt_user.exptId='listcmp-long' \n",
    "#                 AND expt_user.status='RANDOMLY_ASSIGNED')\n",
    "#                 AND log_action.tstamp<'2015-04-01' AND log_action.tstamp>'2014-11-03' ORDER BY log_action.tstamp'''\n",
    "# unique_users = SSH_connection(query_time)\n",
    "# print(unique_users)\n",
    "# curr_time = transition_times.loc[0].at['tstamp']\n",
    "# next_time = transition_times.loc[1].at['tstamp']\n",
    "# print(\"curr time: \", curr_time)\n",
    "# print(\"next_time: \", next_time)\n",
    "# print(next_time - curr_time)\n",
    "# print(type(curr_time))\n",
    "# print(curr_time.total_seconds())\n",
    "\n",
    "# times_dict = {}\n",
    "# actions_dict = {}\n",
    "# t_range = transition_times.shape[0] - 1\n",
    "# prev_time = transition_times.loc[0].at['tstamp']\n",
    "# curr_time = transition_times.loc[10].at['tstamp']\n",
    "# time_diff = curr_time - prev_time\n",
    "\n",
    "# print(time_diff)\n",
    "# print(time_diff.total_seconds())\n",
    "# print(time_diff.second)\n",
    "# print(time_diff.minute)\n",
    "# print(time_diff.hour)\n",
    "\n",
    "# for k in range(t_range):\n",
    "#     user_id = transition_times.loc[k].at['userId']\n",
    "#     curr_action = transition_times.loc[k].at['action']\n",
    "\n",
    "#     if curr_action == 'recommender-change':\n",
    "#         curr_time = transition_times.loc[k].at['tstamp']\n",
    "#         time_diff = curr_time - prev_time\n",
    "#         seconds = time_diff.total_seconds()\n",
    "\n",
    "#         times_dict[user_id] = time_diff + times_dict.get(userId, 0)\n",
    "\n",
    "\n",
    "started_at = {}\n",
    "total_time = {}\n",
    "other_users = set()\n",
    "rows = transition_times.shape[0]\n",
    "# print(rows)\n",
    "# for k in range(rows):\n",
    "#     userId = no_of_users[k].at['userId']\n",
    "#     started_at[userId] = start_times_raw[k].at['tstamp']\n",
    "# print(len(started_at.keys())) #2999\n",
    "\n",
    "for k in range(rows):\n",
    "    userId = transition_times.loc[k].at['userId']\n",
    "    if transition_times.loc[k].at['action'] == 'recommender-change':\n",
    "        diff = transition_times.loc[k].at['tstamp'] - started_at[userId]\n",
    "        # total_time[userId] = diff.total_seconds()\n",
    "        \n",
    "        if diff.total_seconds()<=3600 :\n",
    "            total_time[userId] = diff.total_seconds()\n",
    "        if diff.total_seconds()>3600:\n",
    "            other_users.add(userId)\n",
    "        # if diff.total_seconds()>=3600 and userId in total_time:\n",
    "        #     total_time.pop(userId)\n",
    "\n",
    "# for key in total_time.keys():\n",
    "#     if key in other_users:\n",
    "#         total_time.pop(key)\n",
    "\n",
    "total_time = {key:val for key,val in total_time.items() if key not in other_users}\n",
    "\n",
    "# len = remove_items(total_time, 3600)\n",
    "# print(len)\n",
    "\n",
    "k=0\n",
    "for key,val in total_time.items():\n",
    "    if k <15:\n",
    "        print(key, val)\n",
    "    else:\n",
    "        break\n",
    "    k += 1\n",
    "#536\n",
    "#778\n",
    "#5m 34.7s\n",
    "print(len(total_time))\n",
    "print(len(total_time)/748)\n",
    "print(max(total_time.values()))\n",
    "print(min(total_time.values()))\n",
    "# ORDER BY timestamp \n",
    "# how would you do this for one user sorted by timestamp?\n",
    "# what is the precise output for this problem? what is the output -- to represent the results?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7734ee770e0c8b561a7eea3db918f39df973dd62a4c50ecc5a7d7145864e7eef"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('3.8.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
